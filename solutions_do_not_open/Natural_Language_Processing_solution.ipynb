{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zerotodeeplearning/ztdl-masterclasses/blob/master/solutions_do_not_open/Natural_Language_Processing_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bwH96hViwS7"
   },
   "source": [
    "#### Copyright 2020 Catalit LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFidPKNdkVPg"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvoukA2tkGV4"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfXjY8HxSM9t"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/zerotodeeplearning/ztdl-masterclasses/master/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_path = tf.keras.utils.get_file(\n",
    "    'rotten_tomatoes_positive_reviews.txt',\n",
    "    url + 'rotten_tomatoes_positive_reviews.txt.gz',\n",
    "    extract=True)\n",
    "neg_path = tf.keras.utils.get_file(\n",
    "    'rotten_tomatoes_negative_reviews.txt',\n",
    "    url + 'rotten_tomatoes_negative_reviews.txt.gz',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(pos_path) as fin:\n",
    "  pos_rev = fin.readlines()\n",
    "  pos_rev = [r.decode('utf-8') for r in pos_rev]\n",
    "\n",
    "with gzip.open(neg_path) as fin:\n",
    "  neg_rev = fin.readlines()\n",
    "  neg_rev = [r.decode('utf-8') for r in neg_rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rev[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_rev[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neg_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = np.array(pos_rev + neg_rev)\n",
    "y = np.array([1]*len(pos_rev) + [0]*len(neg_rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(docs, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FY1GV79dWBCK"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "so_58y8XXUYH"
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(docs_train)\n",
    "X_test = vectorizer.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2Pcg6z0Xoma"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "gO1_FkAWWjhb",
    "outputId": "f37cf513-605e-4606-85bd-75102b645d09"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dljENizEWoLm",
    "outputId": "2f323a31-eb4a-4ab8-82c6-31a7de18bffb"
   },
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uGS7WaFzWtyn",
    "outputId": "bd642f85-b9d2-4cd2-ec3e-0800647864d1"
   },
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Feature importances\n",
    "\n",
    "What are the top words indicative of a positive or a negative review? Let's find out:\n",
    "\n",
    "- get the features names from the `vectorizer` using the `.get_feature_names` method\n",
    "- get the features importances from the Logistic Regression using the `.coef_` attribute\n",
    "- wrap the coefficients in a Pandas series, with the names as index and rank them by value\n",
    "- select the top and bottom 20 features and print them\n",
    "- combine the top features into a single list of keywords and name it `top_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgk6FoAcX1eB",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SChsUp5sWwfn",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.coef_[0],\n",
    "                                index=features).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "vJN468QoXzZl",
    "outputId": "b62e5512-e4a9-457e-f817-d5e2eab76ab6",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "top_negative = feature_importances.tail(20)\n",
    "top_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "IcoScQkvX8_1",
    "outputId": "543b8bb3-622a-439d-ba2c-d3a46983bd55",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "top_positive = feature_importances.head(20)\n",
    "top_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "9i9goRnOnj7f",
    "outputId": "a7eda1ce-ad67-4b9d-a498-2e5b62ef478f",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "top_features = list(top_positive.index) + list(top_negative.index)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text exploration with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBw6pkgWaH4h"
   },
   "outputs": [],
   "source": [
    "positive_reviews_concat = ' '.join(pos_rev)\n",
    "negative_reviews_concat = ' '.join(neg_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgLfN4TDnh7A"
   },
   "outputs": [],
   "source": [
    "all_reviews = positive_reviews_concat + negative_reviews_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14zmRSQAZJ0G"
   },
   "outputs": [],
   "source": [
    "all_text = nltk.text.Text(all_reviews.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "woaupkOPYgpE",
    "outputId": "01630a23-6e36-472e-dec9-9adcf3e828b1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "all_text.dispersion_plot(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "1K7OMlWUZ1FT",
    "outputId": "c6d54f06-04a7-4c77-f05b-fdf3972f0f24"
   },
   "outputs": [],
   "source": [
    "all_text.concordance('enjoyable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "aXOEs-wLoPwU",
    "outputId": "7781a828-a720-4c75-bb71-0850553a2cc5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "all_text.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FF8piITHovPW"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "2b9b6af749cf4264ae56eb669ecb0ec8",
      "6eb55b52f92c42699a79d7063598e7c1",
      "86e11e268e734b17bc5e0b1808fdfb29",
      "a52d5dfb472246ffa116930bd9acdfab",
      "01d1003d56aa4852a64ac0ea0cbe5180",
      "f8ee67fd25004b92bbc3495aa0632f1e",
      "fdd88303e15447c29aa6ae1fb92fb9df",
      "eece40336f3144d6b357fedfb8b83dfd"
     ]
    },
    "colab_type": "code",
    "id": "Ur940onyqK9_",
    "outputId": "41b415dd-570b-40a4-f1e9-2f83f8a49d61"
   },
   "outputs": [],
   "source": [
    "tokens = all_reviews.lower().split()\n",
    "\n",
    "clean_tokens = [t for t in tqdm_notebook(tokens) if t not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-y79XYKpdxU"
   },
   "outputs": [],
   "source": [
    "all_text_lower = nltk.text.Text(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "07FKrXn-p_RJ",
    "outputId": "aeded119-89d0-4bbf-c9d7-c61923ffcaec"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "all_text_lower.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pj63FN2Ruu9P"
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_tokenizer = LemmaTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_stop_words = list(np.unique(lemma_tokenizer(' '.join(stop_words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Improve the TFIDF vectorizer\n",
    "\n",
    "Armed with the knowledge acquired in the text analysis, try to improve the configuration of the `TfidfVectorizer`. \n",
    "\n",
    "```python\n",
    "vectorizer = TfidfVectorizer(# YOUR CODE HERE\n",
    ")\n",
    "```\n",
    "\n",
    "- Things you could consider:\n",
    "    - increasing the number of features\n",
    "    - enforcing lowercase\n",
    "    - filtering stop words\n",
    "    - increasing the ngram range\n",
    "    - using the `lemma_tokenizer` defined above\n",
    "- Use the vectorizer to fit and transform the documents\n",
    "- Re-train the `LogisticRegression` model\n",
    "- Did the score improve?\n",
    "- Print out 10 false positives and 10 false negatives and see if you can spot any pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kmh93NHVqDF_",
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=15000,\n",
    "                             lowercase=True,\n",
    "                             stop_words=lemma_stop_words,\n",
    "                             ngram_range=(1, 2),\n",
    "                             tokenizer=lemma_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVctJRCet_4K",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(docs_train)\n",
    "X_test = vectorizer.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "fZPLwLLcuHqT",
    "outputId": "a477bb84-2e0a-40ba-d215-f62ffe93852b",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MrdVvfg4uH-g",
    "outputId": "77c6bbae-3281-4b19-98a3-ebae3d35e8c5",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SCYQecHIuKRO",
    "outputId": "7c260645-96d0-49c5-fd9e-8760786d1830",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZ-EzeKAuMhv",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "dfcm = pd.DataFrame(cm)\n",
    "dfcm.style.bar(color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "#### False positives (label is negative, prediction is positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fp = docs_test[(y_test == 0) & (y_predicted == 1)]\n",
    "\n",
    "for review in fp[:10]:\n",
    "  print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "#### False negatives (label is positive, prediction is negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fn = docs_test[(y_test == 1) & (y_predicted == 0)][:10]\n",
    "\n",
    "for review in fn[:10]:\n",
    "  print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "It looks like both the order and the context of the words are important. We will need to use a model that takes those into account."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "authorship_tag": "ABX9TyOJWB9s6S9wS5YLk8la7mLZ",
   "include_colab_link": true,
   "name": "Natural_Language_Processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
